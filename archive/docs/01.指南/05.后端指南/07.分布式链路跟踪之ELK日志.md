---
title: 分布式链路跟踪之ELK日志
date: 2024-09-01 08:55:50
permalink: /pages/fe2754/
---

你好呀，我的老朋友！我是老寇，欢迎来到老寇云平台！

话不多说，讲一讲分布式链路跟踪之ELK日志！

### 服务治理

在微服务治理中，最重要的莫过于日志、链路和指标，为什么？因为微服务调用链路错综复杂，服务节点的数量成千上万，所以，基础设施建设重中之重，否则，出现问题，排查将是一大难题。

### 技术栈

#### log4j2

[log4j2官方地址](https://logging.apache.org/log4j/2.x/)

像```log4j```、```logback```、```log4j2```都是Java日志记录框架，而slf4j是日志门面，统一日志API，隐藏具体的日志实现。

```log4j2```是```log4j```的升级版，性能卓越，支持异步日志，也是目前性能最好的Java日志记录框架。

```log4j2```不会给Java垃圾回收器带来任何负担，这是通过基于 [LMAX Disruptor](https://lmax-exchange.github.io/disruptor/)
技术和JVM零GC实现

<font color="red">
注意：零gc就是无垃圾回收，log4j2复用字节数组，字符串数组等对象，不需要重复创建，减少不必要的对象创建，从而不触发gc</font>

#### kafka

[kafka官方地址](https://kafka.apache.org/)

什么是事件流处理？

事件流处理是 <font color='red'>从事件源实时捕获数据的做法</font>

例如，从数据库，传感器，移动设备实时捕获数据，持久化存储这些这些事件流以供检索、操作和处理。

`kafka`就是一个事件流处理平台

- 发布（写入）和订阅（读取）事件流，包括连续导入/导出来自其他系统的数据
- 根据需要持久可靠地存储事件流
- 在事件发生时（实时）或回顾性地处理事件流

kafka如何工作？

`kafka`
是一个分布式系统，由服务器和客户端组成，这些服务器和客户端通过高性能 [TCP网络协议](https://kafka.apache.org/protocol.html)
通信。

#### micrometer

[micrometer官方地址](https://docs.micrometer.io/micrometer/reference/)

`micrometer`【千分尺】为最流行的可观测性系统在检测客户端提供了一个简单的外观，允许您检测基于JVM的应用程序代码，而不受供应商限制。

<font color="red">注意：Spring Cloud Sleuth 迁移至 Micrometer Tracing</font>

<font color="red">micrometer是最流行的可观测性工具的应用程序可观测性外观 </font>

<font color="red">tracing是提供对跟踪器和跟踪系统报告器的跟踪抽象</font>

<font color="red">
注意：tracing官方提供对Brave和OpenTelemetry的桥接，tracing只是一个跟踪抽象，类似slf4j门面，具体的链路跟踪由Brave或OpenTelemetry来实现。</font>

```xml

<dependencys>
	<dependency>
		<groupId>io.micrometer</groupId>
		<!-- 集成Brave -->
		<artifactId>micrometer-tracing-bridge-brave</artifactId>
		<version>1.3.3</version>
	</dependency>
	<dependency>
		<groupId>io.micrometer</groupId>
		<!-- 集成OpenTelemetry -->
		<artifactId>micrometer-tracing-bridge-otel</artifactId>
		<version>1.3.3</version>
	</dependency>
</dependencys>
```

Brave和OpenTelemetry区别？

[Brave代码地址](https://github.com/openzipkin/brave)

```Brave```是一个分布式链路跟踪插桩库。通过拦截请求的方式收集时序数据并通过链路标识来关联传播。
通常会将链路跟踪数据发送到```Zipkin```，也可以使用第三方插件方式发送到其他替代服务。

```Brave```提供的API，配置选项较少，但其集成比较简单，适合不需要复杂自定义的场景。

```Brave```主要是围绕```Zipkin```的生态发展，尽管稳定且成熟，但还是有一定的局限性。

---

[OpenTelemetry官方地址](https://opentelemetry.io/)

OpenTelemetry是未来的观测标准【本项目就是使用这个标准，来收集指标和链路】。 提供更广泛的API和配置选项，支持更多自定义的操作，适合需要高度可扩展性和灵活性的应用。

可以用它来检测，生成，收集和导出观测数据【指标、日志和跟踪（链路）】，可以用来分析软件的性能和行为。

更重要是该项目是一个活跃且快速发展的项目，并且得到更广泛的行业支持，具有更广泛的社区支持和更丰富的生态系统，蕴盖了多个云供应商和监控工具。

#### elasticsearch

[elasticsearch官方文档](https://www.elastic.co/cn/elasticsearch)

```elasticsearch```是一个分布式、RESTFul风格的搜索和数据分析引擎，同时是可扩展的数据存储和矢量数据库，能够应对日益增多的各种用例。

<font color="red">注意：什么是矢量？我个人的理解是对某种事物的特征描述，通过特征描述可以大致还原出整个事物</font>

```elasticsearch```能够存储海量数据，实现闪电般的搜索速度，精细的相关性调整以及强大的分析能力，并且能够轻松进行规模扩展。

#### beats

[beats官方地址](https://www.elastic.co/cn/beats)

```beats```是一个免费且开发的平台，集成了多种单一用途数据采集器。它们从成百上千或成千上万台机器和系统向```Logstash```
或```Elasticsearch```发送数据。

##### filebeat

[filebeat官方文档](https://www.elastic.co/cn/beats/filebeat)

```filebeat```是使用```go```语言开发的，用于转发和汇总日志与文件，让简单的事情不再繁杂。

#### logstash

[logstash官方地址](https://www.elastic.co/guide/en/logstash/current/introduction.html)

```logstash```是一个开源数据收集引擎，具有流水线功能，可以动态接收来自不同数据源的数据，并将数据按照一定的规则进行数据清洗，然后写入对应的目标数据源。

任何类型事件可以通过广泛的```input```、```output```、```filter```插件来进行清洗和转换，丰富的编解码器进一步简化开发。

<font color="red">
注意：logstash资源消耗大，占用CPU和内存高，没有消息队列缓存，会有丢失消息的风险，因此，本项目自行写了一个轻量级的服务，用来清洗数据，写入ES。</font>

#### kibana

[kibana官方文档](https://www.elastic.co/guide/en/kibana/current/introduction.html)

```kibana```是一个用户界面，可让您可视化Elasticsearch数据并管理ElasticStack。

- 搜索文档，分析文档和查找安全漏洞
- 数据可视化
- 管理，监控Elastic Stack集群，以及权限控制

#### Elastic Stack

```Elastic Stack```的核心产品包括 Elasticsearch、Kibana、Beats 和 Logstash

ELK = Elasticsearch + Logstash + Kibana

EFK = Elasticsearch + Filebeat + Logstash + Kibana

<img src="/img/分布式链路跟踪之ELK/img.png"/>

### 使用

[es+kibana安装教程](https://kcloud.blog.csdn.net/article/details/138465258)

