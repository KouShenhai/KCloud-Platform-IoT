---
title: 分布式链路跟踪之ELK
date: 2024-09-01 08:55:50
permalink: /pages/fe2754/
---

你好呀，我的老朋友！我是老寇，欢迎来到老寇云平台！

话不多说，讲一讲分布式链路跟踪之ELK！

### 服务治理

在微服务治理中，最重要的莫过于链路和指标，为什么？因为微服务调用链路错综复杂，服务节点的数量成千上万，所以，基础设施建设重中之重，否则，出现问题，排查将是一大难题。

### 架构图

<img src="/img/分布式链路跟踪之ELK/img.png"/>

### 技术栈

#### log4j2

[log4j2官方地址](https://logging.apache.org/log4j/2.x/)

像```log4j```、```logback```、```log4j2```都是Java日志记录框架，而slf4j是日志门面，统一日志API，隐藏具体的日志实现。

```log4j2```是```log4j```的升级版，性能卓越，支持异步日志，也是目前性能最好的Java日志记录框架。

```log4j2```不会给Java垃圾回收器带来任何负担，这是通过基于 [LMAX Disruptor](https://lmax-exchange.github.io/disruptor/)
技术和JVM零GC实现

<font color="red">
注意：零gc就是无垃圾回收，log4j2复用字节数组，字符串数组等对象，不需要重复创建，减少不必要的对象创建，从而不触发gc</font>

#### kafka

[kafka官方地址](https://kafka.apache.org/)

什么是事件流处理？

事件流处理是 <font color='red'>从事件源实时捕获数据的做法</font>

例如，从数据库，传感器，移动设备实时捕获数据，持久化存储这些这些事件流以供检索、操作和处理。

`kafka`就是一个事件流处理平台

- 发布（写入）和订阅（读取）事件流，包括连续导入/导出来自其他系统的数据
- 根据需要持久可靠地存储事件流
- 在事件发生时（实时）或回顾性地处理事件流

kafka如何工作？

`kafka`
是一个分布式系统，由服务器和客户端组成，这些服务器和客户端通过高性能 [TCP网络协议](https://kafka.apache.org/protocol.html)
通信。

#### micrometer

[micrometer官方地址](https://docs.micrometer.io/micrometer/reference/)

`micrometer`【千分尺】为最流行的可观测性系统在检测客户端提供了一个简单的外观，允许您检测基于JVM的应用程序代码，而不受供应商限制。

<font color="red">注意：Spring Cloud Sleuth 迁移至 Micrometer Tracing</font>

<font color="red">micrometer是最流行的可观测性工具的应用程序可观测性外观 </font>

<font color="red">tracing是提供对跟踪器和跟踪系统报告器的跟踪抽象</font>

<font color="red">
注意：tracing官方提供对Brave和OpenTelemetry的桥接，tracing只是一个跟踪抽象，类似slf4j门面，具体的链路跟踪由Brave或OpenTelemetry来实现。</font>

```xml

<dependencys>
	<dependency>
		<groupId>io.micrometer</groupId>
		<artifactId>micrometer-tracing-bridge-brave</artifactId>
		<version>1.3.3</version>
	</dependency>
	<dependency>
		<groupId>io.micrometer</groupId>
		<artifactId>micrometer-tracing-bridge-otel</artifactId>
		<version>1.3.3</version>
	</dependency>
</dependencys>
```

Brave和OpenTelemetry区别？

[Brave代码地址](https://github.com/openzipkin/brave)

```Brave```是一个分布式链路跟踪插桩库。通过拦截请求的方式收集时序数据并通过链路标识来关联传播。
通常会将链路跟踪数据发送到```Zipkin```，也可以用第三方插件方式发送到其他替代服务。

