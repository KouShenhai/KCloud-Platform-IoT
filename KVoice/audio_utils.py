# /*
#  * Copyright (c) 2022-2026 KCloud-Platform-IoT Author or Authors. All Rights Reserved.
#  *
#  * Licensed under the Apache License, Version 2.0 (the "License");
#  * you may not use this file except in compliance with the License.
#  * You may obtain a copy of the License at
#  *
#  *   http://www.apache.org/licenses/LICENSE-2.0
#  *
#  * Unless required by applicable law or agreed to in writing, software
#  * distributed under the License is distributed on an "AS IS" BASIS,
#  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  * See the License for the specific language governing permissions and
#  * limitations under the License.
#  *
#  */

"""
éŸ³é¢‘å¤„ç†å·¥å…·æ¨¡å—
æä¾›å½•éŸ³ã€éŸ³é¢‘åŠ è½½ã€é¢„å¤„ç†ç­‰åŠŸèƒ½
"""

import wave
from pathlib import Path
from typing import Optional, Tuple, Union

import numpy as np

try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False
    print("Warning: PyAudio not installed. Real-time recording disabled.")

try:
    import webrtcvad
    VAD_AVAILABLE = True
except ImportError:
    VAD_AVAILABLE = False
    print("Warning: webrtcvad not installed. VAD features disabled.")

from config import (
    SAMPLE_RATE, CHANNELS, CHUNK_SIZE, RECORD_SECONDS,
	VAD_MODE, VAD_FRAME_DURATION,
    MIN_SPEECH_DURATION, MAX_SILENCE_DURATION
)


class AudioRecorder:
    """å®æ—¶éŸ³é¢‘å½•åˆ¶å™¨"""

    def __init__(self):
        if not PYAUDIO_AVAILABLE:
            raise RuntimeError("PyAudio is required for recording. Install with: pip install pyaudio")
        self.audio = pyaudio.PyAudio()
        self.stream = None

    def __del__(self):
        self.close()

    def close(self):
        """å…³é—­éŸ³é¢‘èµ„æº"""
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
            self.stream = None
        if hasattr(self, 'audio') and self.audio:
            self.audio.terminate()

    def record(self, duration: float = RECORD_SECONDS,
               show_progress: bool = True) -> np.ndarray:
        """
        å½•åˆ¶æŒ‡å®šæ—¶é•¿çš„éŸ³é¢‘

        Args:
            duration: å½•éŸ³æ—¶é•¿(ç§’)
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            éŸ³é¢‘æ•°æ® (numpy array, float32, normalized)
        """
        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )

        frames = []
        num_chunks = int(SAMPLE_RATE / CHUNK_SIZE * duration)

        if show_progress:
            print(f"ğŸ¤ å¼€å§‹å½•éŸ³ ({duration}ç§’)...")

        for i in range(num_chunks):
            data = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            frames.append(data)

            if show_progress and (i + 1) % int(num_chunks / 10) == 0:
                progress = (i + 1) / num_chunks * 100
                print(f"   å½•éŸ³è¿›åº¦: {progress:.0f}%", end='\r')

        if show_progress:
            print("\nâœ… å½•éŸ³å®Œæˆ!")

        self.stream.stop_stream()
        self.stream.close()
        self.stream = None

        # è½¬æ¢ä¸º numpy array
        audio_data = b''.join(frames)
        audio_array = np.frombuffer(audio_data, dtype=np.int16)

        # å½’ä¸€åŒ–åˆ° [-1, 1]
        audio_array = audio_array.astype(np.float32) / 32768.0

        return audio_array

    def record_with_vad(self, max_duration: float = 10.0,
                        min_duration: float = MIN_SPEECH_DURATION,
                        silence_timeout: float = MAX_SILENCE_DURATION) -> Optional[np.ndarray]:
        """
        ä½¿ç”¨ VAD (è¯­éŸ³æ´»åŠ¨æ£€æµ‹) å½•åˆ¶éŸ³é¢‘
        å½“æ£€æµ‹åˆ°é™éŸ³è¶…è¿‡é˜ˆå€¼æ—¶è‡ªåŠ¨åœæ­¢

        Args:
            max_duration: æœ€å¤§å½•éŸ³æ—¶é•¿
            min_duration: æœ€å°è¯­éŸ³æŒç»­æ—¶é—´
            silence_timeout: é™éŸ³è¶…æ—¶æ—¶é—´

        Returns:
            éŸ³é¢‘æ•°æ®ï¼Œå¦‚æœæœªæ£€æµ‹åˆ°è¯­éŸ³åˆ™è¿”å› None
        """
        if not VAD_AVAILABLE:
            print("Warning: VAD not available, using fixed duration recording")
            return self.record(duration=max_duration)

        vad = webrtcvad.Vad(VAD_MODE)

        self.stream = self.audio.open(
            format=pyaudio.paInt16,
            channels=CHANNELS,
            rate=SAMPLE_RATE,
            input=True,
            frames_per_buffer=CHUNK_SIZE
        )

        frames = []
        speech_frames = 0
        silence_frames = 0
        frame_duration = CHUNK_SIZE / SAMPLE_RATE
        min_speech_frames = int(min_duration / frame_duration)
        max_silence_frames = int(silence_timeout / frame_duration)
        max_frames = int(max_duration / frame_duration)

        print("ğŸ¤ å¼€å§‹å½•éŸ³ (æ£€æµ‹åˆ°é™éŸ³åè‡ªåŠ¨åœæ­¢)...")

        for i in range(max_frames):
            data = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
            frames.append(data)

            # VAD æ£€æµ‹éœ€è¦ 16-bit PCM æ•°æ®
            is_speech = self._check_voice_activity(vad, data)

            if is_speech:
                speech_frames += 1
                silence_frames = 0
            else:
                if speech_frames >= min_speech_frames:
                    silence_frames += 1
                    if silence_frames >= max_silence_frames:
                        print("\nâœ… æ£€æµ‹åˆ°é™éŸ³ï¼Œå½•éŸ³ç»“æŸ")
                        break

        self.stream.stop_stream()
        self.stream.close()
        self.stream = None

        if speech_frames < min_speech_frames:
            print("âš ï¸ æœªæ£€æµ‹åˆ°è¶³å¤Ÿçš„è¯­éŸ³")
            return None

        # è½¬æ¢ä¸º numpy array
        audio_data = b''.join(frames)
        audio_array = np.frombuffer(audio_data, dtype=np.int16)
        audio_array = audio_array.astype(np.float32) / 32768.0

        return audio_array

    def _check_voice_activity(self, vad, audio_chunk: bytes) -> bool:
        """æ£€æŸ¥éŸ³é¢‘å—æ˜¯å¦åŒ…å«è¯­éŸ³"""
        try:
            # webrtcvad éœ€è¦ç‰¹å®šå¸§é•¿åº¦çš„æ•°æ®
            frame_size = int(SAMPLE_RATE * VAD_FRAME_DURATION / 1000) * 2
            if len(audio_chunk) >= frame_size:
                return vad.is_speech(audio_chunk[:frame_size], SAMPLE_RATE)
        except Exception:
            pass
        return False


def load_audio(file_path: Union[str, Path]) -> Tuple[np.ndarray, int]:
    """
    åŠ è½½éŸ³é¢‘æ–‡ä»¶

    Args:
        file_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        (éŸ³é¢‘æ•°æ®, é‡‡æ ·ç‡)
    """
    file_path = Path(file_path)

    if file_path.suffix.lower() == '.wav':
        return load_wav(file_path)
    else:
        # ä½¿ç”¨ soundfile æ”¯æŒæ›´å¤šæ ¼å¼
        try:
            import soundfile as sf
            audio, sr = sf.read(file_path)
            if len(audio.shape) > 1:
                audio = audio.mean(axis=1)  # è½¬æ¢ä¸ºå•å£°é“
            return audio.astype(np.float32), sr
        except ImportError:
            raise ValueError(f"Unsupported audio format: {file_path.suffix}")


def load_wav(file_path: Union[str, Path]) -> Tuple[np.ndarray, int]:
    """åŠ è½½ WAV æ–‡ä»¶"""
    with wave.open(str(file_path), 'rb') as wf:
        n_channels = wf.getnchannels()
        sample_width = wf.getsampwidth()
        sample_rate = wf.getframerate()
        n_frames = wf.getnframes()

        audio_data = wf.readframes(n_frames)

    # æ ¹æ®ä½æ·±åº¦è§£ææ•°æ®
    if sample_width == 2:
        audio = np.frombuffer(audio_data, dtype=np.int16)
        audio = audio.astype(np.float32) / 32768.0
    elif sample_width == 4:
        audio = np.frombuffer(audio_data, dtype=np.int32)
        audio = audio.astype(np.float32) / 2147483648.0
    else:
        raise ValueError(f"Unsupported sample width: {sample_width}")

    # è½¬æ¢ä¸ºå•å£°é“
    if n_channels > 1:
        audio = audio.reshape(-1, n_channels).mean(axis=1)

    return audio, sample_rate


def save_wav(audio: np.ndarray, file_path: Union[str, Path],
             sample_rate: int = SAMPLE_RATE):
    """
    ä¿å­˜éŸ³é¢‘ä¸º WAV æ–‡ä»¶

    Args:
        audio: éŸ³é¢‘æ•°æ® (float32, -1 to 1)
        file_path: ä¿å­˜è·¯å¾„
        sample_rate: é‡‡æ ·ç‡
    """
    file_path = Path(file_path)
    file_path.parent.mkdir(parents=True, exist_ok=True)

    # è½¬æ¢ä¸º 16-bit PCM
    audio_int16 = (audio * 32767).clip(-32768, 32767).astype(np.int16)

    with wave.open(str(file_path), 'wb') as wf:
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2)
        wf.setframerate(sample_rate)
        wf.writeframes(audio_int16.tobytes())


def preprocess_audio(audio: np.ndarray, target_sr: int = SAMPLE_RATE) -> np.ndarray:
    """
    éŸ³é¢‘é¢„å¤„ç†

    Args:
        audio: è¾“å…¥éŸ³é¢‘
        target_sr: ç›®æ ‡é‡‡æ ·ç‡

    Returns:
        é¢„å¤„ç†åçš„éŸ³é¢‘
    """
    # å½’ä¸€åŒ–
    if audio.max() > 1.0 or audio.min() < -1.0:
        audio = audio / max(abs(audio.max()), abs(audio.min()))

    # å»é™¤ç›´æµåç§»
    audio = audio - np.mean(audio)

    # ç®€å•çš„é¢„åŠ é‡
    audio = np.append(audio[0], audio[1:] - 0.97 * audio[:-1])

    return audio.astype(np.float32)


def trim_silence(audio: np.ndarray, threshold: float = 0.01,
                 min_silence_len: int = 500) -> np.ndarray:
    """
    å»é™¤éŸ³é¢‘é¦–å°¾é™éŸ³

    Args:
        audio: è¾“å…¥éŸ³é¢‘
        threshold: é™éŸ³é˜ˆå€¼
        min_silence_len: æœ€å°é™éŸ³é•¿åº¦ (é‡‡æ ·ç‚¹)

    Returns:
        å»é™¤é™éŸ³åçš„éŸ³é¢‘
    """
    # è®¡ç®—èƒ½é‡
    energy = np.abs(audio)

    # æ‰¾åˆ°éé™éŸ³åŒºåŸŸ
    mask = energy > threshold

    # æ‰¾åˆ°èµ·å§‹å’Œç»“æŸä½ç½®
    nonzero = np.nonzero(mask)[0]
    if len(nonzero) == 0:
        return audio

    start = max(0, nonzero[0] - min_silence_len)
    end = min(len(audio), nonzero[-1] + min_silence_len)

    return audio[start:end]


def get_audio_duration(audio: np.ndarray, sample_rate: int = SAMPLE_RATE) -> float:
    """è·å–éŸ³é¢‘æ—¶é•¿(ç§’)"""
    return len(audio) / sample_rate


if __name__ == "__main__":
    # æµ‹è¯•å½•éŸ³åŠŸèƒ½
    print("=== éŸ³é¢‘å·¥å…·æµ‹è¯• ===")

    recorder = AudioRecorder()

    print("\n1. æµ‹è¯•å›ºå®šæ—¶é•¿å½•éŸ³ (3ç§’)")
    audio = recorder.record(duration=3)
    print(f"   å½•åˆ¶éŸ³é¢‘é•¿åº¦: {len(audio)} é‡‡æ ·ç‚¹, {get_audio_duration(audio):.2f} ç§’")

    # ä¿å­˜æµ‹è¯•
    test_file = Path(__file__).parent / "test_recording.wav"
    save_wav(audio, test_file)
    print(f"   å·²ä¿å­˜åˆ°: {test_file}")

    # åŠ è½½æµ‹è¯•
    loaded_audio, sr = load_audio(test_file)
    print(f"   é‡æ–°åŠ è½½: {len(loaded_audio)} é‡‡æ ·ç‚¹, é‡‡æ ·ç‡ {sr}")

    recorder.close()
    print("\nâœ… æµ‹è¯•å®Œæˆ!")
