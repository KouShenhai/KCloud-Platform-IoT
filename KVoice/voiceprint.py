# /*
#  * Copyright (c) 2022-2026 KCloud-Platform-IoT Author or Authors. All Rights Reserved.
#  *
#  * Licensed under the Apache License, Version 2.0 (the "License");
#  * you may not use this file except in compliance with the License.
#  * You may obtain a copy of the License at
#  *
#  *   http://www.apache.org/licenses/LICENSE-2.0
#  *
#  * Unless required by applicable law or agreed to in writing, software
#  * distributed under the License is distributed on an "AS IS" BASIS,
#  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  * See the License for the specific language governing permissions and
#  * limitations under the License.
#  *
#  */

"""
å£°çº¹å¤„ç†æ¨¡å—
ä½¿ç”¨ Resemblyzer é¢„è®­ç»ƒæ¨¡å‹æå–å’Œæ¯”å¯¹å£°çº¹ç‰¹å¾
"""

import numpy as np
from typing import List, Tuple, Optional, Union
from pathlib import Path

from config import (
    VOICEPRINT_SIMILARITY_THRESHOLD,
    VOICEPRINT_EMBEDDING_DIM,
    SAMPLE_RATE,
    ENABLE_DEBUG
)

# å»¶è¿Ÿå¯¼å…¥ Resemblyzer (åŠ è½½è¾ƒæ…¢)
_encoder = None


def get_encoder():
    """è·å– Resemblyzer ç¼–ç å™¨ (å•ä¾‹æ¨¡å¼)"""
    global _encoder
    if _encoder is None:
        print("ğŸ”„ åŠ è½½å£°çº¹æ¨¡å‹ (é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦å‡ ç§’)...")
        from resemblyzer import VoiceEncoder
        _encoder = VoiceEncoder()
        print("âœ… å£°çº¹æ¨¡å‹åŠ è½½å®Œæˆ!")
    return _encoder


class VoiceprintEncoder:
    """å£°çº¹ç‰¹å¾ç¼–ç å™¨"""
    
    def __init__(self):
        self.encoder = get_encoder()
        
    def extract_embedding(self, audio: np.ndarray, 
                          sample_rate: int = SAMPLE_RATE) -> np.ndarray:
        """
        ä»éŸ³é¢‘ä¸­æå–å£°çº¹åµŒå…¥å‘é‡
        
        Args:
            audio: éŸ³é¢‘æ•°æ® (float32, -1 to 1)
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            256ç»´å£°çº¹åµŒå…¥å‘é‡
        """
        # Resemblyzer éœ€è¦ float64 æ•°æ®ï¼Œé‡‡æ ·ç‡ 16000
        if audio.dtype != np.float64:
            audio = audio.astype(np.float64)
            
        # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯ 16000ï¼Œéœ€è¦é‡é‡‡æ ·
        if sample_rate != 16000:
            audio = self._resample(audio, sample_rate, 16000)
            
        # æå–åµŒå…¥å‘é‡
        try:
            from resemblyzer import preprocess_wav
            processed = preprocess_wav(audio)
            embedding = self.encoder.embed_utterance(processed)
            return embedding
        except Exception as e:
            if ENABLE_DEBUG:
                print(f"âš ï¸ å£°çº¹æå–å¤±è´¥: {e}")
            # è¿”å›é›¶å‘é‡ä½œä¸ºå¤±è´¥æƒ…å†µ
            return np.zeros(VOICEPRINT_EMBEDDING_DIM, dtype=np.float32)
    
    def extract_embedding_from_file(self, file_path: Union[str, Path]) -> np.ndarray:
        """ä»éŸ³é¢‘æ–‡ä»¶æå–å£°çº¹åµŒå…¥å‘é‡"""
        from audio_utils import load_audio
        audio, sr = load_audio(file_path)
        return self.extract_embedding(audio, sr)
    
    def _resample(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """ç®€å•é‡é‡‡æ ·"""
        if orig_sr == target_sr:
            return audio
        ratio = target_sr / orig_sr
        new_length = int(len(audio) * ratio)
        indices = np.linspace(0, len(audio) - 1, new_length)
        return np.interp(indices, np.arange(len(audio)), audio)
    
    @staticmethod
    def compare_embeddings(emb1: np.ndarray, emb2: np.ndarray) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªå£°çº¹åµŒå…¥å‘é‡çš„ç›¸ä¼¼åº¦ (ä½™å¼¦ç›¸ä¼¼åº¦)
        
        Args:
            emb1: ç¬¬ä¸€ä¸ªåµŒå…¥å‘é‡
            emb2: ç¬¬äºŒä¸ªåµŒå…¥å‘é‡
            
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        # å½’ä¸€åŒ–
        norm1 = np.linalg.norm(emb1)
        norm2 = np.linalg.norm(emb2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
            
        emb1_normalized = emb1 / norm1
        emb2_normalized = emb2 / norm2
        
        # ä½™å¼¦ç›¸ä¼¼åº¦
        similarity = np.dot(emb1_normalized, emb2_normalized)
        
        # ç¡®ä¿åœ¨ [0, 1] èŒƒå›´å†…
        return float(max(0.0, min(1.0, (similarity + 1) / 2)))
    
    @staticmethod
    def is_same_speaker(emb1: np.ndarray, emb2: np.ndarray,
                        threshold: float = VOICEPRINT_SIMILARITY_THRESHOLD) -> Tuple[bool, float]:
        """
        åˆ¤æ–­ä¸¤ä¸ªå£°çº¹æ˜¯å¦å±äºåŒä¸€è¯´è¯äºº
        
        Args:
            emb1: ç¬¬ä¸€ä¸ªåµŒå…¥å‘é‡
            emb2: ç¬¬äºŒä¸ªåµŒå…¥å‘é‡
            threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
            
        Returns:
            (æ˜¯å¦åŒä¸€äºº, ç›¸ä¼¼åº¦åˆ†æ•°)
        """
        similarity = VoiceprintEncoder.compare_embeddings(emb1, emb2)
        return similarity >= threshold, similarity


class VoiceprintMatcher:
    """å£°çº¹åŒ¹é…å™¨ - ç”¨äºä¸æ³¨å†Œç”¨æˆ·è¿›è¡Œå£°çº¹æ¯”å¯¹"""
    
    def __init__(self):
        self.encoder = VoiceprintEncoder()
        self.registered_users = {}  # {user_id: embedding}
        
    def register_user(self, user_id: str, embeddings: List[np.ndarray]) -> np.ndarray:
        """
        æ³¨å†Œç”¨æˆ·å£°çº¹
        
        Args:
            user_id: ç”¨æˆ·ID
            embeddings: å¤šä¸ªå£°çº¹åµŒå…¥å‘é‡åˆ—è¡¨ (ç”¨äºå–å¹³å‡)
            
        Returns:
            å¹³å‡åçš„ç”¨æˆ·å£°çº¹åµŒå…¥å‘é‡
        """
        # è®¡ç®—å¹³å‡åµŒå…¥å‘é‡
        avg_embedding = np.mean(embeddings, axis=0)
        # å½’ä¸€åŒ–
        avg_embedding = avg_embedding / np.linalg.norm(avg_embedding)
        self.registered_users[user_id] = avg_embedding
        
        if ENABLE_DEBUG:
            print(f"âœ… ç”¨æˆ· '{user_id}' å£°çº¹æ³¨å†ŒæˆåŠŸ (åŸºäº {len(embeddings)} ä¸ªæ ·æœ¬)")
            
        return avg_embedding
    
    def unregister_user(self, user_id: str) -> bool:
        """æ³¨é”€ç”¨æˆ·"""
        if user_id in self.registered_users:
            del self.registered_users[user_id]
            return True
        return False
    
    def match(self, audio: np.ndarray, 
              sample_rate: int = SAMPLE_RATE) -> Tuple[Optional[str], float]:
        """
        å°†è¾“å…¥éŸ³é¢‘ä¸æ‰€æœ‰æ³¨å†Œç”¨æˆ·è¿›è¡Œå£°çº¹åŒ¹é…
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘
            sample_rate: é‡‡æ ·ç‡
            
        Returns:
            (åŒ¹é…çš„ç”¨æˆ·ID, æœ€é«˜ç›¸ä¼¼åº¦) å¦‚æœæœªåŒ¹é…è¿”å› (None, 0.0)
        """
        if not self.registered_users:
            return None, 0.0
            
        # æå–è¾“å…¥éŸ³é¢‘çš„å£°çº¹
        input_embedding = self.encoder.extract_embedding(audio, sample_rate)
        
        best_match = None
        best_score = 0.0
        
        for user_id, user_embedding in self.registered_users.items():
            is_match, score = VoiceprintEncoder.is_same_speaker(
                input_embedding, user_embedding
            )
            
            if ENABLE_DEBUG:
                print(f"   - ä¸ç”¨æˆ· '{user_id}' ç›¸ä¼¼åº¦: {score:.4f}")
                
            if score > best_score:
                best_score = score
                if is_match:
                    best_match = user_id
                    
        return best_match, best_score
    
    def match_embedding(self, input_embedding: np.ndarray) -> Tuple[Optional[str], float]:
        """
        ä½¿ç”¨é¢„æå–çš„åµŒå…¥å‘é‡è¿›è¡ŒåŒ¹é…
        
        Args:
            input_embedding: è¾“å…¥éŸ³é¢‘çš„åµŒå…¥å‘é‡
            
        Returns:
            (åŒ¹é…çš„ç”¨æˆ·ID, æœ€é«˜ç›¸ä¼¼åº¦)
        """
        if not self.registered_users:
            return None, 0.0
            
        best_match = None
        best_score = 0.0
        
        for user_id, user_embedding in self.registered_users.items():
            is_match, score = VoiceprintEncoder.is_same_speaker(
                input_embedding, user_embedding
            )
            
            if ENABLE_DEBUG:
                print(f"   - ä¸ç”¨æˆ· '{user_id}' ç›¸ä¼¼åº¦: {score:.4f}")
                
            if score > best_score:
                best_score = score
                if is_match:
                    best_match = user_id
                    
        return best_match, best_score
    
    def get_all_users(self) -> List[str]:
        """è·å–æ‰€æœ‰æ³¨å†Œç”¨æˆ·ID"""
        return list(self.registered_users.keys())
    
    def get_user_embedding(self, user_id: str) -> Optional[np.ndarray]:
        """è·å–ç”¨æˆ·å£°çº¹åµŒå…¥å‘é‡"""
        return self.registered_users.get(user_id)


if __name__ == "__main__":
    # æµ‹è¯•å£°çº¹æ¨¡å—
    print("=== å£°çº¹æ¨¡å—æµ‹è¯• ===\n")
    
    # åˆå§‹åŒ–ç¼–ç å™¨
    encoder = VoiceprintEncoder()
    
    # ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘æ•°æ®
    print("1. æµ‹è¯•å£°çº¹æå–")
    fake_audio = np.random.randn(SAMPLE_RATE * 3).astype(np.float32) * 0.1
    embedding = encoder.extract_embedding(fake_audio)
    print(f"   åµŒå…¥å‘é‡ç»´åº¦: {embedding.shape}")
    print(f"   åµŒå…¥å‘é‡èŒƒå›´: [{embedding.min():.4f}, {embedding.max():.4f}]")
    
    # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
    print("\n2. æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—")
    emb1 = np.random.randn(VOICEPRINT_EMBEDDING_DIM).astype(np.float32)
    emb2 = emb1 + np.random.randn(VOICEPRINT_EMBEDDING_DIM).astype(np.float32) * 0.1
    emb3 = np.random.randn(VOICEPRINT_EMBEDDING_DIM).astype(np.float32)
    
    sim_same = VoiceprintEncoder.compare_embeddings(emb1, emb2)
    sim_diff = VoiceprintEncoder.compare_embeddings(emb1, emb3)
    
    print(f"   ç›¸ä¼¼å£°çº¹ç›¸ä¼¼åº¦: {sim_same:.4f}")
    print(f"   ä¸åŒå£°çº¹ç›¸ä¼¼åº¦: {sim_diff:.4f}")
    
    print("\nâœ… å£°çº¹æ¨¡å—æµ‹è¯•å®Œæˆ!")
