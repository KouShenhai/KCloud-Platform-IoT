# /*
#  * Copyright (c) 2022-2026 KCloud-Platform-IoT Author or Authors. All Rights Reserved.
#  *
#  * Licensed under the Apache License, Version 2.0 (the "License");
#  * you may not use this file except in compliance with the License.
#  * You may obtain a copy of the License at
#  *
#  *   http://www.apache.org/licenses/LICENSE-2.0
#  *
#  * Unless required by applicable law or agreed to in writing, software
#  * distributed under the License is distributed on an "AS IS" BASIS,
#  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  * See the License for the specific language governing permissions and
#  * limitations under the License.
#  *
#  */

"""
å”¤é†’è¯æ£€æµ‹æµ‹è¯•å·¥å…·

å®æ—¶ç›‘å¬éº¦å…‹é£è¾“å…¥ï¼Œæ£€æµ‹å”¤é†’è¯å¹¶ç»Ÿè®¡å‡†ç¡®ç‡
æ”¯æŒå£°çº¹è®¤è¯ï¼šåªæœ‰æ³¨å†Œçš„ç”¨æˆ·æ‰èƒ½å”¤é†’
"""

import os
import sys
import time
import argparse
import numpy as np
import pyaudio
from queue import Queue
from datetime import datetime
from tensorflow import keras

from audio_utils import preprocess_audio
from feature_extractor import extract_features
from speaker_manager import SpeakerManager


class WakeWordTester:
    """å”¤é†’è¯æ£€æµ‹æµ‹è¯•å™¨ï¼ˆæ”¯æŒå£°çº¹éªŒè¯ï¼‰"""

    def __init__(self,
                 model_path: str = "models/wake_word_model.keras",
                 sample_rate: int = 16000,
                 chunk_duration: float = 2.0,
                 wake_threshold: float = 0.7,
                 voice_threshold: float = 0.70,
                 use_voiceprint: bool = False,
                 overlap: float = 0.5):
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨

        Args:
            model_path: å”¤é†’è¯æ¨¡å‹è·¯å¾„
            sample_rate: é‡‡æ ·ç‡
            chunk_duration: æ¯ä¸ªéŸ³é¢‘å—çš„æ—¶é•¿ï¼ˆç§’ï¼‰
            wake_threshold: å”¤é†’è¯æ£€æµ‹é˜ˆå€¼
            voice_threshold: å£°çº¹éªŒè¯é˜ˆå€¼
            use_voiceprint: æ˜¯å¦å¯ç”¨å£°çº¹éªŒè¯
            overlap: éŸ³é¢‘å—é‡å æ¯”ä¾‹
        """
        self.sample_rate = sample_rate
        self.chunk_duration = chunk_duration
        self.wake_threshold = wake_threshold
        self.voice_threshold = voice_threshold
        self.use_voiceprint = use_voiceprint
        self.overlap = overlap

        # è®¡ç®—é‡‡æ ·ç‚¹æ•°
        self.chunk_samples = int(sample_rate * chunk_duration)
        self.step_samples = int(self.chunk_samples * (1 - overlap))

        # åŠ è½½å”¤é†’è¯æ¨¡å‹
        print(f"åŠ è½½å”¤é†’è¯æ¨¡å‹: {model_path}")
        self.model = keras.models.load_model(model_path)
        print("å”¤é†’è¯æ¨¡å‹åŠ è½½æˆåŠŸï¼")

        # åˆå§‹åŒ–å£°çº¹ç®¡ç†å™¨
        if use_voiceprint:
            print("åˆå§‹åŒ–å£°çº¹éªŒè¯...")
            self.speaker_manager = SpeakerManager(threshold=voice_threshold)
            speakers = self.speaker_manager.list_speakers()
            if len(speakers) == 0:
                print("âš ï¸  è­¦å‘Š: æ²¡æœ‰æ³¨å†Œä»»ä½•å£°çº¹ï¼è¯·å…ˆä½¿ç”¨ enroll_speaker.py æ³¨å†Œ")
            else:
                print(f"å·²åŠ è½½ {len(speakers)} ä¸ªå£°çº¹: {', '.join(speakers)}")
        else:
            self.speaker_manager = None

        # PyAudioè®¾ç½®
        self.audio = pyaudio.PyAudio()
        self.stream = None

        # éŸ³é¢‘ç¼“å†²åŒº
        self.audio_buffer = np.array([], dtype=np.float32)
        self.audio_queue = Queue()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_tests': 0,
            'wake_word_detected': 0,
            'voice_verified': 0,
            'voice_rejected': 0,
            'true_positives': 0,
            'false_positives': 0,
            'true_negatives': 0,
            'false_negatives': 0,
            'predictions': [],
            'labels': []
        }

        # æ§åˆ¶æ ‡å¿—
        self.is_running = False

    def start_listening(self):
        """å¼€å§‹ç›‘å¬éº¦å…‹é£"""
        self.stream = self.audio.open(
            format=pyaudio.paFloat32,
            channels=1,
            rate=self.sample_rate,
            input=True,
            frames_per_buffer=1024,
            stream_callback=self._audio_callback
        )
        self.is_running = True
        self.stream.start_stream()

    def stop_listening(self):
        """åœæ­¢ç›‘å¬"""
        self.is_running = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.audio.terminate()

    def _audio_callback(self, in_data, frame_count, time_info, status):
        """éŸ³é¢‘å›è°ƒå‡½æ•°"""
        if self.is_running:
            audio_data = np.frombuffer(in_data, dtype=np.float32)
            self.audio_queue.put(audio_data)
        return (None, pyaudio.paContinue)

    def process_audio(self) -> dict:
        """
        å¤„ç†éŸ³é¢‘å¹¶è¿›è¡Œé¢„æµ‹

        Returns:
            ç»“æœå­—å…¸ æˆ– None
        """
        # ä»é˜Ÿåˆ—æ”¶é›†éŸ³é¢‘æ•°æ®
        while not self.audio_queue.empty():
            chunk = self.audio_queue.get()
            self.audio_buffer = np.concatenate([self.audio_buffer, chunk])

        # å¦‚æœç¼“å†²åŒºè¶³å¤Ÿé•¿ï¼Œè¿›è¡Œé¢„æµ‹
        if len(self.audio_buffer) >= self.chunk_samples:
            # æå–éŸ³é¢‘å—
            audio_chunk = self.audio_buffer[:self.chunk_samples].copy()

            # ç§»åŠ¨ç¼“å†²åŒº
            self.audio_buffer = self.audio_buffer[self.step_samples:]

            # é¢„å¤„ç†
            processed = preprocess_audio(audio_chunk)

            # æå–ç‰¹å¾
            features = extract_features(processed)

            # æ·»åŠ batchç»´åº¦
            features = np.expand_dims(features, axis=0)

            # å”¤é†’è¯é¢„æµ‹
            prediction = self.model.predict(features, verbose=0)[0]
            wake_word_prob = prediction[1]
            is_wake_word = wake_word_prob >= self.wake_threshold

            result = {
                'is_wake_word': is_wake_word,
                'wake_confidence': wake_word_prob,
                'voice_verified': False,
                'voice_similarity': 0.0,
                'speaker_name': '',
                'final_result': False
            }

            # å£°çº¹éªŒè¯
            if is_wake_word and self.use_voiceprint and self.speaker_manager:
                verified, speaker, similarity = self.speaker_manager.verify_speaker(audio_chunk)
                result['voice_verified'] = verified
                result['voice_similarity'] = similarity
                result['speaker_name'] = speaker
                result['final_result'] = verified  # åŒé‡éªŒè¯ï¼šå”¤é†’è¯+å£°çº¹
            else:
                result['final_result'] = is_wake_word and not self.use_voiceprint

            return result

        return None

    def record_and_test(self, label: int, is_authorized: bool = True, duration: float = 2.0):
        """
        å½•åˆ¶éŸ³é¢‘å¹¶æµ‹è¯•

        Args:
            label: çœŸå®æ ‡ç­¾ (1=å”¤é†’è¯, 0=éå”¤é†’è¯)
            is_authorized: æ˜¯å¦ä¸ºæˆæƒç”¨æˆ·
            duration: å½•åˆ¶æ—¶é•¿
        """
        print(f"\n{'='*50}")
        if label == 1:
            if is_authorized:
                print("è¯·è¯´å‡ºå”¤é†’è¯ï¼ˆæˆæƒç”¨æˆ·ï¼‰...")
            else:
                print("è¯·è¯´å‡ºå”¤é†’è¯ï¼ˆæ¨¡æ‹Ÿéæˆæƒç”¨æˆ·ï¼‰...")
        else:
            print("è¯·è¯´ä»»æ„å…¶ä»–è¯è¯­æˆ–ä¿æŒå®‰é™...")
        print(f"{'='*50}")

        # æ¸…ç©ºç¼“å†²åŒº
        self.audio_buffer = np.array([], dtype=np.float32)
        while not self.audio_queue.empty():
            self.audio_queue.get()

        # ç­‰å¾…å½•éŸ³
        time.sleep(duration + 0.5)

        # å¤„ç†éŸ³é¢‘
        result = self.process_audio()

        if result:
            self.stats['total_tests'] += 1

            is_wake = result['is_wake_word']
            final = result['final_result']

            # æ›´æ–°ç»Ÿè®¡
            if is_wake:
                self.stats['wake_word_detected'] += 1

            if self.use_voiceprint:
                if result['voice_verified']:
                    self.stats['voice_verified'] += 1
                elif is_wake:
                    self.stats['voice_rejected'] += 1

            # å¯¹äºå£°çº¹éªŒè¯æ¨¡å¼ï¼ŒæœŸæœ›ç»“æœæ˜¯ï¼šæˆæƒç”¨æˆ·è¯´å”¤é†’è¯æ‰èƒ½é€šè¿‡
            expected = (label == 1 and is_authorized) if self.use_voiceprint else (label == 1)

            if final == expected:
                if final:
                    self.stats['true_positives'] += 1
                else:
                    self.stats['true_negatives'] += 1
            else:
                if final:
                    self.stats['false_positives'] += 1
                else:
                    self.stats['false_negatives'] += 1

            self.stats['predictions'].append(1 if final else 0)
            self.stats['labels'].append(1 if expected else 0)

            # æ˜¾ç¤ºç»“æœ
            print(f"\nå”¤é†’è¯æ£€æµ‹: {'âœ“ é€šè¿‡' if is_wake else 'âœ— æœªé€šè¿‡'} (ç½®ä¿¡åº¦: {result['wake_confidence']:.2%})")

            if self.use_voiceprint and is_wake:
                print(f"å£°çº¹éªŒè¯:   {'âœ“ é€šè¿‡' if result['voice_verified'] else 'âœ— æœªé€šè¿‡'} (ç›¸ä¼¼åº¦: {result['voice_similarity']:.2%})")
                if result['speaker_name']:
                    print(f"åŒ¹é…ç”¨æˆ·:   {result['speaker_name']}")

            correct = final == expected
            color = "\033[92m" if correct else "\033[91m"
            reset = "\033[0m"
            print(f"\næœ€ç»ˆç»“æœ: {'ğŸ”” å”¤é†’æˆåŠŸ' if final else 'ğŸ”‡ æœªå”¤é†’'}")
            print(f"åˆ¤å®š: {color}{'æ­£ç¡®' if correct else 'é”™è¯¯'}{reset}")
        else:
            print("æœªèƒ½è·å–è¶³å¤Ÿçš„éŸ³é¢‘æ•°æ®")

    def continuous_test(self):
        """è¿ç»­æµ‹è¯•æ¨¡å¼"""
        print("\n" + "="*60)
        print("è¿ç»­æµ‹è¯•æ¨¡å¼" + (" (å£°çº¹éªŒè¯å·²å¯ç”¨)" if self.use_voiceprint else ""))
        print("="*60)
        print("å®æ—¶ç›‘æµ‹å”¤é†’è¯ï¼ŒæŒ‰ Ctrl+C åœæ­¢")
        print("-"*60)

        last_detection_time = 0
        detection_cooldown = 2.0

        try:
            while self.is_running:
                result = self.process_audio()

                if result:
                    current_time = time.time()

                    if result['is_wake_word'] and (current_time - last_detection_time) > detection_cooldown:
                        last_detection_time = current_time
                        timestamp = datetime.now().strftime("%H:%M:%S")

                        if self.use_voiceprint:
                            if result['final_result']:
                                print(f"[{timestamp}] ğŸ”” å”¤é†’æˆåŠŸ! ç”¨æˆ·: {result['speaker_name']} "
                                      f"(å”¤é†’è¯: {result['wake_confidence']:.0%}, å£°çº¹: {result['voice_similarity']:.0%})")
                                self.stats['voice_verified'] += 1
                            else:
                                print(f"[{timestamp}] ğŸ”‡ å£°çº¹éªŒè¯å¤±è´¥ "
                                      f"(å”¤é†’è¯: {result['wake_confidence']:.0%}, å£°çº¹: {result['voice_similarity']:.0%})")
                                self.stats['voice_rejected'] += 1
                        else:
                            print(f"[{timestamp}] ğŸ”” æ£€æµ‹åˆ°å”¤é†’è¯ï¼(ç½®ä¿¡åº¦: {result['wake_confidence']:.0%})")

                        self.stats['wake_word_detected'] += 1

                time.sleep(0.05)

        except KeyboardInterrupt:
            print("\nåœæ­¢è¿ç»­æµ‹è¯•...")
            self.print_statistics()

    def interactive_test(self, num_positive: int = 10, num_negative: int = 10):
        """äº¤äº’å¼æµ‹è¯•"""
        print("\n" + "="*60)
        print("äº¤äº’å¼å”¤é†’è¯æ£€æµ‹æµ‹è¯•" + (" (å£°çº¹éªŒè¯å·²å¯ç”¨)" if self.use_voiceprint else ""))
        print("="*60)
        print(f"å°†è¿›è¡Œ {num_positive} æ¬¡å”¤é†’è¯æµ‹è¯•å’Œ {num_negative} æ¬¡éå”¤é†’è¯æµ‹è¯•")
        print("-"*60)

        input("æŒ‰ Enter å¼€å§‹æµ‹è¯•...")

        # æµ‹è¯•å”¤é†’è¯ï¼ˆæ­£æ ·æœ¬ï¼‰
        print(f"\n{'#'*50}")
        print("ç¬¬ä¸€é˜¶æ®µï¼šå”¤é†’è¯æµ‹è¯•ï¼ˆæˆæƒç”¨æˆ·ï¼‰")
        print(f"{'#'*50}")

        for i in range(num_positive):
            print(f"\n[{i+1}/{num_positive}] ", end="")
            input("å‡†å¤‡å¥½åæŒ‰ Enter...")
            self.record_and_test(label=1, is_authorized=True)

        # æµ‹è¯•éå”¤é†’è¯ï¼ˆè´Ÿæ ·æœ¬ï¼‰
        print(f"\n{'#'*50}")
        print("ç¬¬äºŒé˜¶æ®µï¼šéå”¤é†’è¯æµ‹è¯•")
        print(f"{'#'*50}")

        for i in range(num_negative):
            print(f"\n[{i+1}/{num_negative}] ", end="")
            input("å‡†å¤‡å¥½åæŒ‰ Enter...")
            self.record_and_test(label=0)

        self.print_statistics()

    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ç»“æœ"""
        print("\n" + "="*60)
        print("æµ‹è¯•ç»Ÿè®¡ç»“æœ")
        print("="*60)

        total = self.stats['total_tests']
        if total == 0:
            print("è¿˜æ²¡æœ‰è¿›è¡Œä»»ä½•æµ‹è¯•")
            return

        tp = self.stats['true_positives']
        fp = self.stats['false_positives']
        tn = self.stats['true_negatives']
        fn = self.stats['false_negatives']

        accuracy = (tp + tn) / total if total > 0 else 0
        precision = tp / (tp + fp) if (tp + fp) > 0 else 0
        recall = tp / (tp + fn) if (tp + fn) > 0 else 0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0

        print(f"\næ€»æµ‹è¯•æ¬¡æ•°: {total}")
        print(f"å”¤é†’è¯æ£€æµ‹: {self.stats['wake_word_detected']} æ¬¡")

        if self.use_voiceprint:
            print(f"å£°çº¹éªŒè¯é€šè¿‡: {self.stats['voice_verified']} æ¬¡")
            print(f"å£°çº¹éªŒè¯æ‹’ç»: {self.stats['voice_rejected']} æ¬¡")

        print(f"\næ··æ·†çŸ©é˜µ:")
        print(f"  {'':12} | é¢„æµ‹:é€šè¿‡ | é¢„æµ‹:æ‹’ç»")
        print(f"  {'-'*40}")
        print(f"  {'çœŸå®:é€šè¿‡':12} | {tp:^8} | {fn:^8}")
        print(f"  {'çœŸå®:æ‹’ç»':12} | {fp:^8} | {tn:^8}")

        print(f"\næ€§èƒ½æŒ‡æ ‡:")
        print(f"  å‡†ç¡®ç‡ (Accuracy):  {accuracy:.2%}")
        print(f"  ç²¾ç¡®ç‡ (Precision): {precision:.2%}")
        print(f"  å¬å›ç‡ (Recall):    {recall:.2%}")
        print(f"  F1 åˆ†æ•°:            {f1:.2%}")
        print(f"  è¯¯æŠ¥ç‡ (FPR):       {fpr:.2%}")
        print(f"  æ¼æŠ¥ç‡ (FNR):       {fnr:.2%}")

        print("\n" + "="*60)

        # è¯„ä¼°
        print("\nğŸ“Š è¯„ä¼°ç»“è®º:")
        if accuracy >= 0.9:
            print("  âœ… ç³»ç»Ÿè¡¨ç°ä¼˜ç§€ï¼å‡†ç¡®ç‡è¾¾åˆ°90%ä»¥ä¸Š")
        elif accuracy >= 0.8:
            print("  âš ï¸ ç³»ç»Ÿè¡¨ç°è‰¯å¥½ï¼Œä½†ä»æœ‰æ”¹è¿›ç©ºé—´")
        elif accuracy >= 0.7:
            print("  âš ï¸ ç³»ç»Ÿè¡¨ç°ä¸€èˆ¬ï¼Œå»ºè®®è¡¥å……æ›´å¤šè®­ç»ƒæ•°æ®")
        else:
            print("  âŒ ç³»ç»Ÿè¡¨ç°è¾ƒå·®ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæˆ–è°ƒæ•´å‚æ•°")


def main():
    parser = argparse.ArgumentParser(description="å”¤é†’è¯æ£€æµ‹æµ‹è¯•å·¥å…·ï¼ˆæ”¯æŒå£°çº¹éªŒè¯ï¼‰")
    parser.add_argument("--model", "-m", type=str,
                        default="models/wake_word_model.keras",
                        help="å”¤é†’è¯æ¨¡å‹è·¯å¾„")
    parser.add_argument("--mode", type=str, default="interactive",
                        choices=["interactive", "continuous"],
                        help="æµ‹è¯•æ¨¡å¼")
    parser.add_argument("--voiceprint", "-v", action="store_true",
                        help="å¯ç”¨å£°çº¹éªŒè¯ï¼ˆéœ€å…ˆä½¿ç”¨ enroll_speaker.py æ³¨å†Œï¼‰")
    parser.add_argument("--positive", "-p", type=int, default=5,
                        help="æ­£æ ·æœ¬æµ‹è¯•æ¬¡æ•°")
    parser.add_argument("--negative", "-n", type=int, default=5,
                        help="è´Ÿæ ·æœ¬æµ‹è¯•æ¬¡æ•°")
    parser.add_argument("--wake-threshold", type=float, default=0.7,
                        help="å”¤é†’è¯æ£€æµ‹é˜ˆå€¼ (0.0-1.0, é»˜è®¤ 0.7)")
    parser.add_argument("--voice-threshold", type=float, default=0.70,
                        help="å£°çº¹éªŒè¯é˜ˆå€¼ (0.0-1.0)")
    parser.add_argument("--duration", "-d", type=float, default=2.0,
                        help="æ¯æ¬¡å½•éŸ³æ—¶é•¿ï¼ˆç§’ï¼‰")

    args = parser.parse_args()

    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.model):
        print(f"é”™è¯¯: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {args.model}")
        print("è¯·å…ˆè¿è¡Œ python model_demo.py è®­ç»ƒæ¨¡å‹")
        sys.exit(1)

    # åˆ›å»ºæµ‹è¯•å™¨
    tester = WakeWordTester(
        model_path=args.model,
        wake_threshold=args.wake_threshold,
        voice_threshold=args.voice_threshold,
        use_voiceprint=args.voiceprint,
        chunk_duration=args.duration
    )

    try:
        tester.start_listening()
        mode_str = "å£°çº¹éªŒè¯å·²å¯ç”¨" if args.voiceprint else "ä»…å”¤é†’è¯æ£€æµ‹"
        print(f"\nğŸ¤ éº¦å…‹é£å·²å¯åŠ¨ ({mode_str})")

        if args.mode == "interactive":
            tester.interactive_test(
                num_positive=args.positive,
                num_negative=args.negative
            )
        else:
            tester.continuous_test()

    except Exception as e:
        print(f"é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    finally:
        tester.stop_listening()
        print("\næµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
