# /*
#  * Copyright (c) 2022-2026 KCloud-Platform-IoT Author or Authors. All Rights Reserved.
#  *
#  * Licensed under the Apache License, Version 2.0 (the "License");
#  * you may not use this file except in compliance with the License.
#  * You may obtain a copy of the License at
#  *
#  *   http://www.apache.org/licenses/LICENSE-2.0
#  *
#  * Unless required by applicable law or agreed to in writing, software
#  * distributed under the License is distributed on an "AS IS" BASIS,
#  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  * See the License for the specific language governing permissions and
#  * limitations under the License.
#  *
#  */

"""
å”¤é†’è¯æ£€æµ‹æ¨¡å—
ä½¿ç”¨ Whisper ASR è¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œæ£€æµ‹"ä½ å¥½ä¸–ç•Œ"å”¤é†’è¯
"""

import re
from typing import Tuple

import numpy as np

from config import (
	WAKE_WORD,
	WAKE_WORD_VARIANTS,
	WHISPER_MODEL,
	WHISPER_LANGUAGE,
	SAMPLE_RATE,
	ENABLE_DEBUG
)

# å»¶è¿Ÿå¯¼å…¥ Whisper (åŠ è½½è¾ƒæ…¢)
_whisper_model = None


def get_whisper_model():
    """è·å– Whisper æ¨¡å‹ (å•ä¾‹æ¨¡å¼)"""
    global _whisper_model
    if _whisper_model is None:
        print(f"ğŸ”„ åŠ è½½ Whisper æ¨¡å‹ ({WHISPER_MODEL})...")
        import whisper
        _whisper_model = whisper.load_model(WHISPER_MODEL)
        print("âœ… Whisper æ¨¡å‹åŠ è½½å®Œæˆ!")
    return _whisper_model


class WakeWordDetector:
    """å”¤é†’è¯æ£€æµ‹å™¨"""

    def __init__(self, wake_word: str = WAKE_WORD):
        """
        åˆå§‹åŒ–å”¤é†’è¯æ£€æµ‹å™¨

        Args:
            wake_word: å”¤é†’è¯ (é»˜è®¤ "ä½ å¥½ä¸–ç•Œ")
        """
        self.wake_word = wake_word
        self.model = get_whisper_model()

        # é¢„ç¼–è¯‘å”¤é†’è¯åŒ¹é…æ¨¡å¼
        self.wake_patterns = self._build_patterns()

    def _build_patterns(self) -> list:
        """æ„å»ºå”¤é†’è¯åŒ¹é…æ¨¡å¼"""
        patterns = []

        # æ·»åŠ æ ‡å‡†å”¤é†’è¯å˜ä½“
        for variant in WAKE_WORD_VARIANTS:
            # ç§»é™¤ç©ºæ ¼å’Œæ ‡ç‚¹è¿›è¡ŒåŒ¹é…
            normalized = self._normalize_text(variant)
            patterns.append(normalized)

        # æ·»åŠ è‡ªå®šä¹‰å”¤é†’è¯
        if self.wake_word not in WAKE_WORD_VARIANTS:
            patterns.append(self._normalize_text(self.wake_word))

        return patterns

    def _normalize_text(self, text: str) -> str:
        """è§„èŒƒåŒ–æ–‡æœ¬ç”¨äºåŒ¹é…"""
        # ç§»é™¤ç©ºæ ¼ã€æ ‡ç‚¹
        text = re.sub(r'[,ï¼Œ.ã€‚!ï¼?ï¼Ÿ\s]', '', text.lower())
        return text

    def transcribe(self, audio: np.ndarray,
                   sample_rate: int = SAMPLE_RATE) -> str:
        """
        ä½¿ç”¨ Whisper è½¬å½•éŸ³é¢‘

        Args:
            audio: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡

        Returns:
            è½¬å½•æ–‡æœ¬
        """
        # Whisper éœ€è¦ float32 æ•°æ®
        if audio.dtype != np.float32:
            audio = audio.astype(np.float32)

        # å¦‚æœé‡‡æ ·ç‡ä¸æ˜¯ 16000ï¼Œéœ€è¦é‡é‡‡æ ·
        if sample_rate != 16000:
            audio = self._resample(audio, sample_rate, 16000)

        try:
            # è½¬å½•
            result = self.model.transcribe(
                audio,
                language=WHISPER_LANGUAGE,
                fp16=False,  # CPU æ¨¡å¼
                verbose=False
            )

            text = result.get('text', '').strip()

            if ENABLE_DEBUG:
                print(f"   ğŸ“ Whisper è½¬å½•: \"{text}\"")

            return text

        except Exception as e:
            if ENABLE_DEBUG:
                print(f"âš ï¸ Whisper è½¬å½•å¤±è´¥: {e}")
            return ""

    def detect_wake_word(self, audio: np.ndarray,
                         sample_rate: int = SAMPLE_RATE) -> Tuple[bool, str, float]:
        """
        æ£€æµ‹éŸ³é¢‘ä¸­æ˜¯å¦åŒ…å«å”¤é†’è¯

        Args:
            audio: éŸ³é¢‘æ•°æ®
            sample_rate: é‡‡æ ·ç‡

        Returns:
            (æ˜¯å¦æ£€æµ‹åˆ°å”¤é†’è¯, è¯†åˆ«çš„æ–‡æœ¬, åŒ¹é…ç½®ä¿¡åº¦)
        """
        # è½¬å½•éŸ³é¢‘
        text = self.transcribe(audio, sample_rate)

        if not text:
            return False, "", 0.0

        # æ£€æµ‹å”¤é†’è¯
        is_match, confidence = self.is_wake_word_match(text)

        return is_match, text, confidence

    def is_wake_word_match(self, text: str) -> Tuple[bool, float]:
        """
        æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ¹é…å”¤é†’è¯

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            (æ˜¯å¦åŒ¹é…, ç½®ä¿¡åº¦åˆ†æ•°)
        """
        normalized_text = self._normalize_text(text)

        # ç²¾ç¡®åŒ¹é…æ£€æŸ¥
        for pattern in self.wake_patterns:
            if pattern in normalized_text:
                return True, 1.0

        # æ¨¡ç³ŠåŒ¹é… - è®¡ç®—ç¼–è¾‘è·ç¦»
        best_similarity = 0.0
        primary_pattern = self._normalize_text(WAKE_WORD)  # ä½ å¥½ä¸–ç•Œ

        # ä½¿ç”¨æ»‘åŠ¨çª—å£æ£€æŸ¥ç›¸ä¼¼åº¦
        window_size = len(primary_pattern)
        for i in range(max(1, len(normalized_text) - window_size + 1)):
            window = normalized_text[i:i + window_size]
            similarity = self._calculate_similarity(window, primary_pattern)
            best_similarity = max(best_similarity, similarity)

        # å¦‚æœæ•´ä½“ç›¸ä¼¼åº¦ä¹Ÿå¾ˆé«˜ï¼Œè€ƒè™‘åŒ¹é…
        overall_similarity = self._calculate_similarity(normalized_text, primary_pattern)
        best_similarity = max(best_similarity, overall_similarity)

        # é˜ˆå€¼ 0.8 è®¤ä¸ºæ˜¯åŒ¹é…
        is_match = best_similarity >= 0.8

        if ENABLE_DEBUG and best_similarity > 0.5:
            print(f"   ğŸ” å”¤é†’è¯åŒ¹é…ç›¸ä¼¼åº¦: {best_similarity:.2%}")

        return is_match, best_similarity

    def _calculate_similarity(self, s1: str, s2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ (1 - å½’ä¸€åŒ–ç¼–è¾‘è·ç¦»)"""
        if not s1 or not s2:
            return 0.0

        # ç®€åŒ–çš„ Levenshtein è·ç¦»
        len1, len2 = len(s1), len(s2)

        if len1 == 0:
            return 0.0
        if len2 == 0:
            return 0.0

        # åˆ›å»ºè·ç¦»çŸ©é˜µ
        dp = [[0] * (len2 + 1) for _ in range(len1 + 1)]

        for i in range(len1 + 1):
            dp[i][0] = i
        for j in range(len2 + 1):
            dp[0][j] = j

        for i in range(1, len1 + 1):
            for j in range(1, len2 + 1):
                cost = 0 if s1[i - 1] == s2[j - 1] else 1
                dp[i][j] = min(
                    dp[i - 1][j] + 1,      # åˆ é™¤
                    dp[i][j - 1] + 1,      # æ’å…¥
                    dp[i - 1][j - 1] + cost  # æ›¿æ¢
                )

        distance = dp[len1][len2]
        max_len = max(len1, len2)

        return 1.0 - (distance / max_len)

    def _resample(self, audio: np.ndarray, orig_sr: int, target_sr: int) -> np.ndarray:
        """ç®€å•é‡é‡‡æ ·"""
        if orig_sr == target_sr:
            return audio
        ratio = target_sr / orig_sr
        new_length = int(len(audio) * ratio)
        indices = np.linspace(0, len(audio) - 1, new_length)
        return np.interp(indices, np.arange(len(audio)), audio).astype(np.float32)


def detect_wake_word_simple(text: str) -> bool:
    """
    ç®€å•çš„å”¤é†’è¯æ£€æµ‹ (ä»…åŸºäºæ–‡æœ¬åŒ¹é…)
    ç”¨äºå·²ç»å®Œæˆ ASR è½¬å½•çš„åœºæ™¯

    Args:
        text: è¾“å…¥æ–‡æœ¬

    Returns:
        æ˜¯å¦åŒ…å«å”¤é†’è¯
    """
    # è§„èŒƒåŒ–æ–‡æœ¬
    normalized = re.sub(r'[,ï¼Œ.ã€‚!ï¼?ï¼Ÿ\s]', '', text.lower())

    # æ£€æŸ¥æ‰€æœ‰å”¤é†’è¯å˜ä½“
    for variant in WAKE_WORD_VARIANTS:
        variant_normalized = re.sub(r'[,ï¼Œ.ã€‚!ï¼?ï¼Ÿ\s]', '', variant.lower())
        if variant_normalized in normalized:
            return True

    return False


if __name__ == "__main__":
    # æµ‹è¯•å”¤é†’è¯æ£€æµ‹
    print("=== å”¤é†’è¯æ£€æµ‹æµ‹è¯• ===\n")

    # åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = WakeWordDetector()

    # æµ‹è¯•æ–‡æœ¬åŒ¹é…
    print("1. æµ‹è¯•æ–‡æœ¬åŒ¹é…")
    test_cases = [
        "ä½ å¥½ä¸–ç•Œ",
        "ä½ å¥½ï¼Œä¸–ç•Œ",
        "ä¸–ç•Œä½ å¥½",
        "ä½ å¥½å°æ˜",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
        "ni hao xiao yun",
    ]

    for text in test_cases:
        is_match, confidence = detector.is_wake_word_match(text)
        status = "âœ…" if is_match else "âŒ"
        print(f"   {status} \"{text}\" -> åŒ¹é…: {is_match}, ç½®ä¿¡åº¦: {confidence:.2%}")

    # æµ‹è¯•éŸ³é¢‘è½¬å½• (å¦‚æœæœ‰éŸ³é¢‘è®¾å¤‡)
    print("\n2. æµ‹è¯•éŸ³é¢‘è½¬å½•")
    try:
        from audio_utils import AudioRecorder

        print("   è¯·è¯´è¯ (3ç§’)...")
        recorder = AudioRecorder()
        audio = recorder.record(duration=3)
        recorder.close()

        is_wake, text, conf = detector.detect_wake_word(audio)
        print(f"   è¯†åˆ«æ–‡æœ¬: \"{text}\"")
        print(f"   å”¤é†’è¯æ£€æµ‹: {'âœ… æ˜¯' if is_wake else 'âŒ å¦'}")
        print(f"   ç½®ä¿¡åº¦: {conf:.2%}")

    except Exception as e:
        print(f"   âš ï¸ éŸ³é¢‘æµ‹è¯•è·³è¿‡: {e}")

    print("\nâœ… å”¤é†’è¯æ£€æµ‹æµ‹è¯•å®Œæˆ!")
